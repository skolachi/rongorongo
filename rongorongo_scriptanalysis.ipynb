{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rongorongo-scriptanalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMb86NR++44B06oShv1eXQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skolachi/rongorongo/blob/master/rongorongo_scriptanalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8pOb5y6ikPV"
      },
      "outputs": [],
      "source": [
        "!wget http://kohaumotu.org/rongorongo_org/concord/concord1.zip\n",
        "!wget http://kohaumotu.org/rongorongo_org/concord/concord2.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir rongorongo\n",
        "!unzip concord1.zip -d rongorongo/ \n",
        "!unzip concord2.zip -d rongorongo/\n",
        "!rm concord1.zip concord2.zip\n",
        "!cat rongorongo/*.CCD >> rongorongo/fullconcordance.CCD\n",
        "!wc -l rongorongo/fullconcordance.CCD"
      ],
      "metadata": {
        "id": "cYpw5gn6ltNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def read_corpus(corpusfile):\n",
        "  return re.findall(r'[A-Z]{1}[a-z]{1}[0-9]{2}\\.[0-9]{3}\\:([^\\n]*)',open(corpusfile).read())"
      ],
      "metadata": {
        "id": "7uKTILtwpdVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = read_corpus('rongorongo/fullconcordance.CCD')\n",
        "len(corpus)\n",
        "corpus[:10]"
      ],
      "metadata": {
        "id": "GUO7TWfrp2dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#punctuation = ['-','.',':','\\'','*']\n",
        "samp = ''\n",
        "def line2sign(line):\n",
        "  signs = []\n",
        "  line = re.sub('\\([0-9]{1}\\-[0-9]{1}\\)','-000-',line)\n",
        "  for c in re.split(r'[\\-\\.\\:\\'\\*]',line):\n",
        "    if c != '':\n",
        "      sign = re.sub('[^0-9]','',c)\n",
        "      signs.append('0'*(3-len(sign))+sign)\n",
        "  \n",
        "  return signs"
      ],
      "metadata": {
        "id": "xyUf7CBHuaxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sign_sequences.txt','w') as f:\n",
        "  for text in corpus:\n",
        "    f.write('{}\\n'.format(' '.join(line2sign(text))))"
      ],
      "metadata": {
        "id": "GK7HaDzR7Qmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "wIEGtaW6KGnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tokenizers import Tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "from tokenizers.models import Unigram, WordLevel, WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import decoders"
      ],
      "metadata": {
        "id": "oDU1MHV0LWAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tokenizer():\n",
        "  dictfiles = ['sign_sequences.txt']\n",
        "\n",
        "  tokenizer = BertWordPieceTokenizer()\n",
        "  tokenizer.pre_tokenizer = Whitespace()\n",
        "  tokenizer.decoder = decoders.WordPiece()\n",
        "\n",
        "  tokenizer.train(files=dictfiles,min_frequency=2,special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"])\n",
        "  if not os.path.isdir(\"rongorongoLM\"):\n",
        "    os.mkdir(\"rongorongoLM\")\n",
        "  tokenizer.save_model(\"rongorongoLM\")"
      ],
      "metadata": {
        "id": "gm9p1IQMLwJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenizer()\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"rongorongoLM\")"
      ],
      "metadata": {
        "id": "qG9pf59zMMet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "  tokenizer=tokenizer,\n",
        "  file_path=\"./sign_sequences.txt\",\n",
        "  block_size=128,\n",
        ")\n"
      ],
      "metadata": {
        "id": "P8HryRmtMnSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig(\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=6,\n",
        "    num_hidden_layers=3,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "metadata": {
        "id": "-uCf7W8zNKfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM\n",
        "\n",
        "model = BertForMaskedLM(config=config)\n",
        "\n",
        "print(\"Number of model parameters: \",model.num_parameters())"
      ],
      "metadata": {
        "id": "K7UMfb6ANR5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "-mpOjO_uNhZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "def train_lm():\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./rongorongoLM\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=1,\n",
        "        per_gpu_train_batch_size=128,\n",
        "        save_steps=10_000,\n",
        "        save_total_limit=2,\n",
        "        prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(\"./rongorongoLM\")"
      ],
      "metadata": {
        "id": "KKux84CiORRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lm()"
      ],
      "metadata": {
        "id": "GrCgBDnZOips"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "  \"fill-mask\",\n",
        "  model=\"./rongorongoLM\",\n",
        "  tokenizer=\"./rongorongoLM\"\n",
        ")"
      ],
      "metadata": {
        "id": "UXSsGpzYWnaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[10], ' '.join(line2sign(corpus[10]))"
      ],
      "metadata": {
        "id": "2GcU5-FrW-u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask(\"004 000 000 004 [MASK] 000 000 001 000 [MASK] 008 600 001 385 001 000 059 022 022 008\")"
      ],
      "metadata": {
        "id": "sGo57iokXUJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}